{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bd1dff9-9c27-4e57-a5e1-bfa6dca1201a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loaded 2225 articles.\n",
      "[INFO] 2225 articles remain after preprocessing.\n",
      "[INFO] TF-IDF matrix shape: (2225, 5000)\n",
      "[INFO] Calculating Inertia for Elbow Method (k in [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15])...\n",
      "  - Inertia for k=1: 2159.01\n",
      "  - Inertia for k=2: 2140.89\n",
      "  - Inertia for k=3: 2121.47\n",
      "  - Inertia for k=4: 2106.65\n",
      "  - Inertia for k=5: 2087.66\n",
      "  - Inertia for k=6: 2078.24\n",
      "  - Inertia for k=7: 2068.74\n",
      "  - Inertia for k=8: 2058.69\n",
      "  - Inertia for k=9: 2051.29\n",
      "  - Inertia for k=10: 2042.15\n",
      "  - Inertia for k=11: 2037.68\n",
      "  - Inertia for k=12: 2031.63\n",
      "  - Inertia for k=13: 2025.09\n",
      "  - Inertia for k=14: 2019.72\n",
      "  - Inertia for k=15: 2015.68\n",
      "[INFO] Saved Elbow Method plot to: elbow_method_plot.png\n",
      "[INFO] Searching for best k (Silhouette) in range: [2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  - Silhouette score for k=2: 0.0081\n",
      "  - Silhouette score for k=3: 0.0124\n",
      "  - Silhouette score for k=4: 0.0134\n",
      "  - Silhouette score for k=5: 0.0157\n",
      "  - Silhouette score for k=6: 0.0157\n",
      "  - Silhouette score for k=7: 0.0173\n",
      "  - Silhouette score for k=8: 0.0168\n",
      "  - Silhouette score for k=9: 0.0179\n",
      "  - Silhouette score for k=10: 0.0187\n",
      "[INFO] Saved silhouette score plot to: silhouette_scores.png\n",
      "[INFO] Selected k=5 for final clustering based on ground truth / silhouette score.\n",
      "\n",
      "--- Top Keywords per Cluster ---\n",
      "Cluster 0: film, best, awards, award, festival, films, actor, oscar, director, actress, star, won\n",
      "Cluster 1: game, england, win, said, cup, match, team, players, injury, play, club, season\n",
      "Cluster 2: said, growth, economy, bank, year, market, company, sales, mr, oil, firm, shares\n",
      "Cluster 3: said, people, music, mobile, new, mr, technology, tv, software, uk, digital, users\n",
      "Cluster 4: mr, labour, election, blair, said, party, brown, government, howard, minister, tory, prime\n",
      "\n",
      "--- Clustering Evaluation vs. Folder Labels ---\n",
      "Adjusted Rand Index (ARI): 0.6812\n",
      "Normalized Mutual Info (NMI): 0.7335\n",
      "Homogeneity: 0.7159\n",
      "Completeness: 0.7520\n",
      "V-measure: 0.7335\n",
      "[INFO] Saved evaluation metrics to: evaluation_metrics.txt\n",
      "[INFO] Running t-SNE for visualization...\n",
      "[INFO] Saved t-SNE visualization to: tsne_visualization.png\n",
      "[TIMER] Visualization generation finished in 6.82 seconds.\n",
      "[INFO] Generating confusion matrix and cluster distribution plots...\n",
      "[INFO] Saved confusion matrix plot to: confusion_matrix.png\n",
      "[INFO] Saved cluster distribution plot to: cluster_distribution.png\n",
      "[INFO] Saved results to: clustered_articles.csv\n",
      "[TIMER] Total execution time finished in 10.08 seconds.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import string\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, ENGLISH_STOP_WORDS\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import (\n",
    "    silhouette_score,\n",
    "    adjusted_rand_score,\n",
    "    normalized_mutual_info_score,\n",
    "    homogeneity_score,\n",
    "    completeness_score,\n",
    "    v_measure_score,\n",
    "    confusion_matrix\n",
    ")\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    PLOTTING_ENABLED = True\n",
    "except ImportError:\n",
    "    PLOTTING_ENABLED = False\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "ROOT_FOLDER = \"bbc\" \n",
    "OUTPUT_CSV = \"clustered_articles.csv\"\n",
    "OUTPUT_METRICS = \"evaluation_metrics.txt\"\n",
    "OUTPUT_CONFUSION_MATRIX_PLOT = \"confusion_matrix.png\"\n",
    "OUTPUT_CLUSTER_DISTRIBUTION_PLOT = \"cluster_distribution.png\"\n",
    "OUTPUT_SILHOUETTE_PLOT = \"silhouette_scores.png\"\n",
    "OUTPUT_ELBOW_PLOT = \"elbow_method_plot.png\"  # <-- New plot output\n",
    "OUTPUT_TSNE_PLOT = \"tsne_visualization.png\"\n",
    "\n",
    "MAX_TFIDF_FEATURES = 5000\n",
    "K_SEARCH_RANGE = range(2, 11) # For silhouette\n",
    "K_ELBOW_RANGE = range(1, 16)   # For elbow method\n",
    "SVD_COMPONENTS = 50\n",
    "TSNE_PERPLEXITY = 30\n",
    "TSNE_RANDOM_STATE = 42\n",
    "MAX_TSNE_SAMPLES = 3000\n",
    "# ----------------------------------------\n",
    "\n",
    "# --- DUMMY DATA SETUP ---\n",
    "def create_dummy_data():\n",
    "    if os.path.exists(ROOT_FOLDER): return\n",
    "    print(\"[SETUP] Creating dummy data for demonstration...\")\n",
    "    # (Dummy data creation logic remains the same)\n",
    "    categories = {\n",
    "        \"business\": [\"dollar rises\", \"stock market rally\", \"corporate profits soar\"],\n",
    "        \"sport\": [\"england wins rugby\", \"chelsea league title\", \"federer wins tennis\"],\n",
    "        \"tech\": [\"new smartphone\", \"broadband speeds increase\", \"social media grows\"],\n",
    "        \"entertainment\": [\"blockbuster film\", \"new music album\", \"award ceremony honors actors\"],\n",
    "        \"politics\": [\"election campaign\", \"government new policy\", \"parliament debates bill\"]\n",
    "    }\n",
    "    os.makedirs(ROOT_FOLDER, exist_ok=True)\n",
    "    for category, articles in categories.items():\n",
    "        cat_path = os.path.join(ROOT_FOLDER, category)\n",
    "        os.makedirs(cat_path, exist_ok=True)\n",
    "        for i, article in enumerate(articles):\n",
    "            with open(os.path.join(cat_path, f\"{i+1:03d}.txt\"), \"w\") as f:\n",
    "                f.write((article + \" \") * 20)\n",
    "\n",
    "# --- UTILITY FUNCTIONS ---\n",
    "def log(message): print(f\"[INFO] {message}\")\n",
    "def log_timer(message, start_time): print(f\"[TIMER] {message} finished in {time.time() - start_time:.2f} seconds.\")\n",
    "\n",
    "STOP_WORDS = set(ENGLISH_STOP_WORDS)\n",
    "\n",
    "def load_articles_from_subfolders(root_folder):\n",
    "    root = Path(root_folder)\n",
    "    if not root.is_dir():\n",
    "        log(f\"ERROR: ROOT_FOLDER '{root_folder}' not found.\"), sys.exit(1)\n",
    "    records = []\n",
    "    for fpath in sorted(root.glob(\"**/*.txt\")):\n",
    "        txt = fpath.read_text(encoding=\"utf-8\", errors=\"ignore\").strip()\n",
    "        if not txt: continue\n",
    "        category = fpath.parent.name if fpath.parent != root else None\n",
    "        records.append({\"filename\": fpath.name, \"category\": category, \"text\": txt})\n",
    "    return pd.DataFrame.from_records(records)\n",
    "\n",
    "def preprocess(text, stop_words=STOP_WORDS):\n",
    "    t = text.lower()\n",
    "    t = t.translate(str.maketrans(string.punctuation, \" \" * len(string.punctuation)))\n",
    "    return \" \".join([tok for tok in t.split() if tok not in stop_words and len(tok) > 1])\n",
    "\n",
    "# --- CLUSTERING ANALYSIS FUNCTIONS ---\n",
    "def find_best_k_silhouette(X, k_range):\n",
    "    best_k, best_score, scores = None, -1.0, {}\n",
    "    log(f\"Searching for best k (Silhouette) in range: {list(k_range)}\")\n",
    "    for k in k_range:\n",
    "        labels = KMeans(n_clusters=k, random_state=42, n_init='auto').fit_predict(X)\n",
    "        score = silhouette_score(X, labels)\n",
    "        scores[k] = score\n",
    "        print(f\"  - Silhouette score for k={k}: {score:.4f}\")\n",
    "        if score > best_score: best_score, best_k = score, k\n",
    "    return best_k, scores\n",
    "\n",
    "def top_keywords_per_cluster(vectorizer, kmeans, n_terms=12):\n",
    "    terms = vectorizer.get_feature_names_out()\n",
    "    order = kmeans.cluster_centers_.argsort()[:, ::-1]\n",
    "    return {i: [terms[ind] for ind in order[i, :n_terms]] for i in range(len(kmeans.cluster_centers_))}\n",
    "\n",
    "# --- PLOTTING FUNCTIONS ---\n",
    "\n",
    "def plot_elbow_method(X, k_range):\n",
    "    \"\"\"\n",
    "    NEW: Calculates and plots the WCSS (Inertia) for a range of k values.\n",
    "    \"\"\"\n",
    "    if not PLOTTING_ENABLED: return\n",
    "    log(f\"Calculating Inertia for Elbow Method (k in {list(k_range)})...\")\n",
    "    inertia_values = []\n",
    "    for k in k_range:\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42, n_init='auto')\n",
    "        kmeans.fit(X)\n",
    "        inertia_values.append(kmeans.inertia_)\n",
    "        print(f\"  - Inertia for k={k}: {kmeans.inertia_:.2f}\")\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(k_range, inertia_values, marker='o', linestyle='--')\n",
    "    plt.title(\"Elbow Method for Optimal k\")\n",
    "    plt.xlabel(\"Number of Clusters (k)\")\n",
    "    plt.ylabel(\"Within-Cluster Sum of Squares (WCSS / Inertia)\")\n",
    "    plt.xticks(k_range)\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUTPUT_ELBOW_PLOT)\n",
    "    log(f\"Saved Elbow Method plot to: {OUTPUT_ELBOW_PLOT}\"), plt.close()\n",
    "\n",
    "\n",
    "def plot_silhouette_scores(scores, best_k):\n",
    "    if not PLOTTING_ENABLED or not scores: return\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(list(scores.keys()), list(scores.values()), marker='o', linestyle='--')\n",
    "    plt.title(\"Silhouette Score vs. Number of Clusters (k)\")\n",
    "    plt.xlabel(\"k\"), plt.ylabel(\"Silhouette Score\")\n",
    "    if best_k: plt.axvline(x=best_k, color='r', linestyle='--', label=f'Best k = {best_k}')\n",
    "    plt.legend(), plt.grid(True), plt.tight_layout()\n",
    "    plt.savefig(OUTPUT_SILHOUETTE_PLOT)\n",
    "    log(f\"Saved silhouette score plot to: {OUTPUT_SILHOUETTE_PLOT}\"), plt.close()\n",
    "\n",
    "def plot_tsne_visualization(X, df):\n",
    "    # (This function remains the same)\n",
    "    if not PLOTTING_ENABLED or not (3 <= X.shape[0] <= MAX_TSNE_SAMPLES): return\n",
    "    log(\"Running t-SNE for visualization...\")\n",
    "    start_time_viz = time.time()\n",
    "    n_svd = min(SVD_COMPONENTS, X.shape[0] - 1, X.shape[1] - 1)\n",
    "    if n_svd < 2: return\n",
    "    X_red = TruncatedSVD(n_components=n_svd, random_state=42).fit_transform(X)\n",
    "    perplexity = min(TSNE_PERPLEXITY, X_red.shape[0] - 1)\n",
    "    if perplexity < 5: return\n",
    "    X_tsne = TSNE(n_components=2, perplexity=perplexity, random_state=TSNE_RANDOM_STATE, init=\"random\").fit_transform(X_red)\n",
    "    df_plot = df.copy()\n",
    "    df_plot['tsne_1'], df_plot['tsne_2'] = X_tsne[:, 0], X_tsne[:, 1]\n",
    "    \n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.scatterplot(data=df_plot, x='tsne_1', y='tsne_2', hue='cluster', palette='tab10', s=80, legend='full')\n",
    "    plt.title('t-SNE Visualization of Clusters'), plt.xlabel('t-SNE Dimension 1'), plt.ylabel('t-SNE Dimension 2')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUTPUT_TSNE_PLOT)\n",
    "    log(f\"Saved t-SNE visualization to: {OUTPUT_TSNE_PLOT}\"), plt.close()\n",
    "    log_timer(\"Visualization generation\", start_time_viz)\n",
    "\n",
    "def plot_cluster_analysis(df):\n",
    "    # (This function remains the same)\n",
    "    if not PLOTTING_ENABLED or df[\"category\"].isnull().all(): return\n",
    "    log(\"Generating confusion matrix and cluster distribution plots...\")\n",
    "    y_true, y_pred = df[\"category\"], df[\"cluster\"]\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    labels, cluster_labels = sorted(y_true.unique()), sorted(y_pred.unique())\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=cluster_labels, yticklabels=labels)\n",
    "    plt.title('Confusion Matrix: True Category vs. Predicted Cluster'), plt.xlabel('Predicted Cluster'), plt.ylabel('True Category')\n",
    "    plt.tight_layout(), plt.savefig(OUTPUT_CONFUSION_MATRIX_PLOT), plt.close()\n",
    "    log(f\"Saved confusion matrix plot to: {OUTPUT_CONFUSION_MATRIX_PLOT}\")\n",
    "    \n",
    "    crosstab = pd.crosstab(df['cluster'], df['category'])\n",
    "    crosstab.div(crosstab.sum(axis=1), axis=0).plot(kind='bar', stacked=True, figsize=(12, 8), colormap='tab20')\n",
    "    plt.title('Distribution of True Categories within Each Cluster'), plt.xlabel('Predicted Cluster'), plt.ylabel('Proportion')\n",
    "    plt.legend(title='Category', bbox_to_anchor=(1.05, 1), loc='upper left'), plt.tight_layout()\n",
    "    plt.savefig(OUTPUT_CLUSTER_DISTRIBUTION_PLOT), plt.close()\n",
    "    log(f\"Saved cluster distribution plot to: {OUTPUT_CLUSTER_DISTRIBUTION_PLOT}\")\n",
    "\n",
    "# --- MAIN PIPELINE ---\n",
    "if __name__ == \"__main__\":\n",
    "    total_start_time = time.time()\n",
    "    create_dummy_data()\n",
    "\n",
    "    df = load_articles_from_subfolders(ROOT_FOLDER)\n",
    "    log(f\"Loaded {len(df)} articles.\")\n",
    "    if df.empty: sys.exit(1)\n",
    "\n",
    "    df[\"clean_text\"] = df[\"text\"].apply(preprocess)\n",
    "    df = df[df[\"clean_text\"].str.strip().astype(bool)].reset_index(drop=True)\n",
    "    log(f\"{len(df)} articles remain after preprocessing.\")\n",
    "\n",
    "    vectorizer = TfidfVectorizer(max_features=MAX_TFIDF_FEATURES)\n",
    "    X = vectorizer.fit_transform(df[\"clean_text\"])\n",
    "    log(f\"TF-IDF matrix shape: {X.shape}\")\n",
    "\n",
    "    # --- Find Optimal k ---\n",
    "    plot_elbow_method(X, K_ELBOW_RANGE) # <-- Call the new Elbow Method plot function\n",
    "    best_k_sil, sil_scores = find_best_k_silhouette(X, K_SEARCH_RANGE)\n",
    "    plot_silhouette_scores(sil_scores, best_k_sil)\n",
    "    \n",
    "    # --- Final Clustering ---\n",
    "    num_categories = df['category'].nunique()\n",
    "    final_k = num_categories if num_categories > 1 else (best_k_sil if best_k_sil else 5)\n",
    "    log(f\"Selected k={final_k} for final clustering based on ground truth / silhouette score.\")\n",
    "\n",
    "    kmeans = KMeans(n_clusters=final_k, random_state=42, n_init='auto')\n",
    "    df[\"cluster\"] = kmeans.fit_predict(X)\n",
    "    df['cluster'] = 'Cluster ' + df['cluster'].astype(str)\n",
    "\n",
    "    print(\"\\n--- Top Keywords per Cluster ---\")\n",
    "    for c, terms in top_keywords_per_cluster(vectorizer, kmeans).items():\n",
    "        print(f\"Cluster {c}: {', '.join(terms)}\")\n",
    "\n",
    "    # --- Evaluation ---\n",
    "    if df[\"category\"].notnull().any():\n",
    "        y_true, y_pred = df[\"category\"], df[\"cluster\"]\n",
    "        metrics = {\"Adjusted Rand Index (ARI)\": adjusted_rand_score(y_true, y_pred),\n",
    "                   \"Normalized Mutual Info (NMI)\": normalized_mutual_info_score(y_true, y_pred),\n",
    "                   \"Homogeneity\": homogeneity_score(y_true, y_pred),\n",
    "                   \"Completeness\": completeness_score(y_true, y_pred),\n",
    "                   \"V-measure\": v_measure_score(y_true, y_pred)}\n",
    "        print(\"\\n--- Clustering Evaluation vs. Folder Labels ---\")\n",
    "        with open(OUTPUT_METRICS, \"w\") as f:\n",
    "            for name, score in metrics.items():\n",
    "                line = f\"{name}: {score:.4f}\"\n",
    "                print(line), f.write(line + \"\\n\")\n",
    "        log(f\"Saved evaluation metrics to: {OUTPUT_METRICS}\")\n",
    "\n",
    "    # --- Visualization ---\n",
    "    plot_tsne_visualization(X, df)\n",
    "    plot_cluster_analysis(df)\n",
    "\n",
    "    df.to_csv(OUTPUT_CSV, index=False)\n",
    "    log(f\"Saved results to: {OUTPUT_CSV}\")\n",
    "\n",
    "    log_timer(\"Total execution time\", total_start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b6d9b2-67b4-443a-af18-271ffe4b6c03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
